{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3efc247",
   "metadata": {},
   "source": [
    "# Burgers' Equation\n",
    "## A 1+1 Dimensional Numerical Experiment of FNOs\n",
    "\n",
    "This notebooks walks through the Fourier Neural Operator for a 1D problem such as the (time-independent) Burgers equation discussed in Section 5.1 in the paper [Fourier Neural Operator for\n",
    "Parametric Partial Differential Equations](https://arxiv.org/pdf/2010.08895.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9247f693-2cd8-4b1d-870b-cea99313b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import \n",
    "\n",
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer\n",
    "\n",
    "from torch.nn.functional import mse_loss\n",
    "import torch\n",
    "\n",
    "from neuralop.models import FNO1d\n",
    "from neuralop.datasets import load_burgers\n",
    "from neuralop import count_params\n",
    "from neuralop.training import LpLoss\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed002e-87b3-43b3-af50-cc8998b5ddc9",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The following configurations control the training and evaluation of the FNO model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3a52fe-8ae0-4d3e-8a8d-9d4a09353a3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'widgets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_filepath_input \u001b[38;5;241m=\u001b[39m \u001b[43mwidgets\u001b[49m\u001b[38;5;241m.\u001b[39mTextarea(\n\u001b[0;32m      2\u001b[0m     value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124morang\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mneuraloperator\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mburgers_data_R10.pth\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFilepath:\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     tooltip\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFully qualified file path to training/testing data.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     disabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Training parameters:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m n_train_input \u001b[38;5;241m=\u001b[39m widgets\u001b[38;5;241m.\u001b[39mIntText(\n\u001b[0;32m     10\u001b[0m     value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m     11\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining size:\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m     tooltip\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining set size\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m     disabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'widgets' is not defined"
     ]
    }
   ],
   "source": [
    "data_filepath_input = widgets.Textarea(\n",
    "    value='C:\\\\Users\\\\orang\\\\code\\\\neuraloperator\\\\data\\\\burgers_data_R10.pth',\n",
    "    description='Filepath:',\n",
    "    tooltip='Fully qualified file path to training/testing data.',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Training parameters:\n",
    "n_train_input = widgets.IntText(\n",
    "    value=1000,\n",
    "    description='Training size:',\n",
    "    tooltip='Training set size',\n",
    "    disabled=False\n",
    ")\n",
    "n_test_input = widgets.IntText(\n",
    "    value=100,\n",
    "    description='Testing size:',\n",
    "    tooltip='Testing set size',\n",
    "    disabled=False\n",
    ")\n",
    "subsampling_rate_input = widgets.IntText(\n",
    "    value=2**3,\n",
    "    description='Subsampling rate:',\n",
    "    tooltip='Subsampling rate:',\n",
    "    disabled=False\n",
    ")\n",
    "h_input = widgets.IntText(\n",
    "    value=(2**13) // subsampling_rate_input.value,\n",
    "    description='H:',\n",
    "    disabled=False\n",
    ")\n",
    "s_input = widgets.IntText(\n",
    "    value=h_input.value,\n",
    "    description='S:',\n",
    "    disabled=False\n",
    ")\n",
    "batch_size_input = widgets.IntText(\n",
    "    value=32,\n",
    "    description='Batch size:',\n",
    "    disabled=False\n",
    ")\n",
    "learning_rate_input = widgets.FloatText(\n",
    "    value=0.001,\n",
    "    description='Learning rate:',\n",
    "    disabled=False\n",
    ")\n",
    "epochs_input = widgets.FloatText(\n",
    "    value=20,\n",
    "    description='Epochs:',\n",
    "    disabled=False\n",
    ")\n",
    "iterations_input = widgets.FloatText(\n",
    "    value=epochs_input.value * (n_train_input.value // batch_size_input.value),\n",
    "    description='Iterations:',\n",
    "    disabled=False\n",
    ")\n",
    "modes_input = widgets.FloatText(\n",
    "    value=16,\n",
    "    description='Modes count:',\n",
    "    disabled=False\n",
    ")\n",
    "width_input = widgets.FloatText(\n",
    "    value=64,\n",
    "    description='Width:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(data_filepath_input)\n",
    "display(n_train_input)\n",
    "display(n_test_input)\n",
    "display(subsampling_rate_input)\n",
    "display(h_input)\n",
    "display(s_input)\n",
    "display(batch_size_input)\n",
    "display(learning_rate_input)\n",
    "display(epochs_input)\n",
    "display(iterations_input)\n",
    "display(modes_input)\n",
    "display(width_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0439dfb-4c71-465e-93bd-cf8ea5e29d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# read data\n",
    "################################################################\n",
    "\n",
    "# Data is of the shape (number of samples, grid size)\n",
    "# FIXME colab link: https://drive.google.com/drive/folders/1UnbQh2WWc6knEHbLn-ZaXrKUZhp7pjt-?usp=sharing\n",
    "# FIXME add zenodo link or streaming (latter for colab)\n",
    "train_loader, test_loader = load_burgers(\n",
    "    data_filepath_input.value, \n",
    "    n_train_input.value, \n",
    "    n_test_input.value,\n",
    "    batch_test=1\n",
    ")\n",
    "\n",
    "# Get the shape of outputs (for later testing) from the first testing data point\n",
    "for _, y in test_loader:\n",
    "    y_test_shape = y.shape\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e0379b-6847-4a5c-9f48-69048f0ceb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME model = FNO1d(modes, width, use_mlp=True, mlp_expansion=1.0).cuda()\n",
    "model = FNO1d(\n",
    "    # modes_height : number of Fourier modes to keep along the height\n",
    "    int(modes_input.value),\n",
    "\n",
    "    # hidden_channels : width of the FNO (i.e. number of channels)\n",
    "    int(width_input.value),\n",
    "    \n",
    "    in_channels=2,\n",
    "    use_mlp=True,\n",
    "    decompostion_kwargs={'dtype', torch.cdouble},\n",
    "    fno_block_precision='double',\n",
    "    dtype=torch.float64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a51fbca-a301-4071-b4f9-df1d208d5c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter count: 312897\n",
      "FNO1d(\n",
      "  (fno_blocks): FNOBlocks(\n",
      "    (convs): SpectralConv(\n",
      "      (weight): ModuleList(\n",
      "        (0-3): 4 x ComplexDenseTensor(shape=torch.Size([64, 64, 8]), rank=None)\n",
      "      )\n",
      "    )\n",
      "    (fno_skips): ModuleList(\n",
      "      (0-3): 4 x Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    )\n",
      "    (mlp): ModuleList(\n",
      "      (0-3): 4 x MLP(\n",
      "        (fcs): ModuleList(\n",
      "          (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
      "          (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mlp_skips): ModuleList(\n",
      "      (0-3): 4 x SoftGating()\n",
      "    )\n",
      "  )\n",
      "  (lifting): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv1d(2, 64, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (projection): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(256, 1, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Model parameter count:\", count_params(model))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1046228d-278d-46cd-b082-4b121276f947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 0\n",
      "Duration:      32.66292\n",
      "Training MSE:   0.00206\n",
      "Training L2:    0.07703\n",
      "Testing L2:     2.15096\n",
      "================================\n",
      "Epoch # 1\n",
      "Duration:      34.55830\n",
      "Training MSE:   0.00018\n",
      "Training L2:    0.03113\n",
      "Testing L2:     1.63485\n",
      "================================\n",
      "Epoch # 2\n",
      "Duration:      32.42625\n",
      "Training MSE:   0.00012\n",
      "Training L2:    0.02581\n",
      "Testing L2:     1.62641\n",
      "================================\n",
      "Epoch # 3\n",
      "Duration:      31.57399\n",
      "Training MSE:   0.00011\n",
      "Training L2:    0.02389\n",
      "Testing L2:     1.38830\n",
      "================================\n",
      "Epoch # 4\n",
      "Duration:      32.69845\n",
      "Training MSE:   0.00008\n",
      "Training L2:    0.02111\n",
      "Testing L2:     1.23056\n",
      "================================\n",
      "Epoch # 5\n",
      "Duration:      31.79896\n",
      "Training MSE:   0.00007\n",
      "Training L2:    0.01940\n",
      "Testing L2:     1.14220\n",
      "================================\n",
      "Epoch # 6\n",
      "Duration:      30.07474\n",
      "Training MSE:   0.00006\n",
      "Training L2:    0.01733\n",
      "Testing L2:     1.07133\n",
      "================================\n",
      "Epoch # 7\n",
      "Duration:      29.52180\n",
      "Training MSE:   0.00005\n",
      "Training L2:    0.01613\n",
      "Testing L2:     1.03132\n",
      "================================\n",
      "Epoch # 8\n",
      "Duration:      30.30093\n",
      "Training MSE:   0.00005\n",
      "Training L2:    0.01563\n",
      "Testing L2:     1.01007\n",
      "================================\n",
      "Epoch # 9\n",
      "Duration:      31.17392\n",
      "Training MSE:   0.00005\n",
      "Training L2:    0.01549\n",
      "Testing L2:     1.00940\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# training and evaluation\n",
    "################################################################\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate_input.value, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=iterations_input.value)\n",
    "\n",
    "loss = LpLoss()  # Does not do size averaging\n",
    "for ep in range(int(epochs_input.value)):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    # Mean Squared Error;\n",
    "    # will be measured pointwise on predicted field function u(x, t)\n",
    "    # for each discretized point (i.e. by x-value).\n",
    "    train_mse = 0  \n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader:\n",
    "        # FIXME x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # from IPython.core import debugger as ipdb; ipdb.set_trace()\n",
    "        # print('x.shape=', x.shape)\n",
    "        out = model(x)\n",
    "\n",
    "        mse = mse_loss(\n",
    "            out.view(batch_size_input.value, -1),\n",
    "            y.view(batch_size_input.value, -1), \n",
    "            reduction='mean'\n",
    "        )\n",
    "        l2 = loss(\n",
    "            out.view(batch_size_input.value, -1),\n",
    "            y.view(batch_size_input.value, -1)\n",
    "        )\n",
    "        l2.backward() # use the l2 relative loss\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_mse += mse.item()\n",
    "        train_l2 += l2.item()\n",
    "\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            # FIXME x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            out = model(x)\n",
    "            test_l2 += loss(\n",
    "                out.view(batch_size_input.value, -1),\n",
    "                y.view(batch_size_input.value, -1)\n",
    "            ).item()\n",
    "\n",
    "    train_mse /= len(train_loader)\n",
    "    train_l2 /= n_train_input.value\n",
    "    test_l2 /= n_test_input.value\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(\n",
    "        f'Epoch # {ep}',\n",
    "        f'Duration:     {t2-t1:9.5f}',\n",
    "        f'Training MSE: {train_mse:9.5f}',\n",
    "        f'Training L2:  {train_l2:9.5f}',\n",
    "        f'Testing L2:   {test_l2:9.5f}',\n",
    "        '=' * 32,\n",
    "        sep='\\n',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c381f44-6261-4940-8a82-237949ed94d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = torch.zeros(len(test_loader), *(y_test_shape[1:]))\n",
    "index = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        test_l2 = 0\n",
    "        # FIXME x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        out = model(x)\n",
    "        pred[index] = out.view(-1)\n",
    "\n",
    "        test_l2 += loss(out.view(1, -1), y.view(1, -1)).item()\n",
    "        # print(index, test_l2)\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afeb3c63-0fa8-4cce-adcb-2f50f56a589e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_samples \u001b[38;5;241m=\u001b[39m \u001b[43mtest_loader\u001b[49m\u001b[38;5;241m.\u001b[39mdataset\n\u001b[0;32m      4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(axs\u001b[38;5;241m.\u001b[39mflat):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_samples = test_loader.dataset\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 6))\n",
    "for index, ax in enumerate(axs.flat):\n",
    "    data = test_samples[index * 20]\n",
    "    # Input ``a`` & Ground-truth ``u``\n",
    "    a, u = data\n",
    "    # Model prediction\n",
    "    out = model(a.unsqueeze(0))\n",
    "    ax.plot(a[0], label=\"Input `x`\")\n",
    "    ax.plot(u.squeeze(), label=\"Ground-truth `y`\")\n",
    "    ax.plot(out.squeeze().detach().numpy(), label=\"Model prediction\")\n",
    "    plt.xticks([], [])\n",
    "\n",
    "fig.suptitle('Inputs, ground-truth output and prediction.', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ed1e3-5d5d-4085-92d6-b3620a902766",
   "metadata": {},
   "source": [
    "We can barely see the Ground Truth curve above, so the model's prediction already aggrees with the solver to within a small error. Moreover, this is only within 20 epochs of training. Real-world applications would be trained for much longer - on the order of 500 epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
