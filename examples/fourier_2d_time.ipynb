{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navier-Stokes Equation\n",
    "## A 2+1 Dimensional Numerical Experiment of FNOs\n",
    "\n",
    "This notebook walks through the Fourier Neural Operator for a 2D problem such as the Navier-Stokes discussed in Section 5.3 in the paper [Fourier Neural Operator for\n",
    "Parametric Partial Differential Equations](https://arxiv.org/pdf/2010.08895.pdf) which uses a recurrent structure to propagates in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Generic, NamedTuple, Optional, TypeVar\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer\n",
    "\n",
    "from torch.nn.functional import mse_loss\n",
    "import torch\n",
    "\n",
    "from neuralop import count_params\n",
    "from neuralop.datasets import load_navier_stokes_temporal_pt\n",
    "from neuralop.layers import SpectralConv2d\n",
    "from neuralop.models import FNO2d\n",
    "from neuralop.training import LpLoss\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "# Utilities\n",
    "#################################################\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The overall network. It contains 4 layers of the Fourier layer.\n",
      "1. Lift the input to the desire channel dimension by self.fc0 .\n",
      "2. 4 layers of the integral operators u' = (W + K)(u).\n",
      "    W defined by self.w; K defined by self.conv .\n",
      "3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
      "\n",
      "input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
      "input shape: (batchsize, x=64, y=64, c=12)\n",
      "output: the solution of the next timestep\n",
      "output shape: (batchsize, x=64, y=64, c=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# fourier layer\n",
    "################################################################\n",
    "print(\n",
    "\"\"\"\n",
    "The overall network. It contains 4 layers of the Fourier layer.\n",
    "1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "    W defined by self.w; K defined by self.conv .\n",
    "3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "\n",
    "input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
    "input shape: (batchsize, x=64, y=64, c=12)\n",
    "output: the solution of the next timestep\n",
    "output shape: (batchsize, x=64, y=64, c=1)\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.epochs: 500\n"
     ]
    }
   ],
   "source": [
    "class Config(NamedTuple):\n",
    "    train_path: str\n",
    "    test_path: str\n",
    "    n_train: int\n",
    "    n_test: int\n",
    "    train_batch_size: int\n",
    "    test_batch_size: int\n",
    "    learning_rate: float\n",
    "    epochs: int\n",
    "    iterations: int\n",
    "    modes: int\n",
    "    width: int\n",
    "    subsampling_rate: int\n",
    "    s: int\n",
    "    history_length: int\n",
    "    future_duration: int\n",
    "    step: int\n",
    "        \n",
    "    @staticmethod\n",
    "    def from_yaml(config_path: str):\n",
    "        with open(config_path, 'r') as f:\n",
    "            cfg = yaml.load(f)\n",
    "\n",
    "        config = Config(\n",
    "            train_path=cfg['train_path'],\n",
    "            test_path=cfg['test_path'],\n",
    "            n_train=cfg['n_train'],\n",
    "            n_test=cfg['n_test'],\n",
    "            train_batch_size=cfg['train_batch_size'],\n",
    "            test_batch_size=cfg['test_batch_size'],\n",
    "            learning_rate=cfg['learning_rate'],\n",
    "            epochs=cfg['epochs'],\n",
    "            iterations=cfg['iterations'],\n",
    "            modes=cfg['modes'],\n",
    "            width=cfg['width'],\n",
    "            subsampling_rate=cfg['subsampling_rate'],\n",
    "            s=cfg['s'],\n",
    "            history_length=cfg['history_length'],\n",
    "            future_duration=cfg['future_duration'],\n",
    "            step=cfg['step'],\n",
    "        )        \n",
    "        return config\n",
    "\n",
    "\n",
    "config = Config.from_yaml('fourier_2d_time_V1e-3.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitGaussianNormalizer init on 1000, reducing over [0, 1, 2, 3], samples of shape [10, 64, 64].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n",
      "UnitGaussianNormalizer init on 1000, reducing over [0, 1, 2, 3], samples of shape [40, 64, 64].\n",
      "   Mean and std of shape torch.Size([1, 1, 1]), eps=1e-05\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# load data and data normalization\n",
    "################################################################\n",
    "\n",
    "# Assumes there exist training and testing data .pt files at\n",
    "# `neuralop/data/ns_data_V100_N1000_T50_1.pt`, and\n",
    "# `neuralop/data/ns_data_V100_N1000_T50_1.pt`\n",
    "train_loader, test_loader, output_encoder = load_navier_stokes_temporal_pt(\n",
    "    config.train_path, # Currently, the same path is used for both training and testing data.\n",
    "    config.n_train,\n",
    "    config.n_test,\n",
    "    config.history_length,\n",
    "    config.future_duration,\n",
    "    config.train_batch_size,\n",
    "    config.test_batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter count: 239773\n"
     ]
    }
   ],
   "source": [
    "model = FNO2d(\n",
    "    config.modes,  # modes_width\n",
    "    config.modes,  # modes_height\n",
    "    config.width,  # width of all hidden layers\n",
    "    # input channels are 12: the solution of the previous 10 timesteps + 2 location encodings\n",
    "    # i.e: (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
    "    in_channels=2 + config.history_length,\n",
    "    out_channels=1,  # output channel is 1: u(t, x, y)\n",
    "    n_layers=4,\n",
    "    # domain_padding=8,\n",
    "    domain_padding=None,\n",
    "    # domain_padding_mode='one-sided',\n",
    "    use_mlp=True,\n",
    ").cuda()\n",
    "print(f\"Model parameter count: {count_params(model):,d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 000 / 500\n",
      "Duration:      25.06834\n",
      "Training L2 (step):   0.55194\n",
      "Training L2 (full):   1.29020\n",
      "Testing L2 (step):    0.53796\n",
      "Testing L2 (full):    1.33653\n",
      "================================\n",
      "Epoch # 001 / 500\n",
      "Duration:      24.81722\n",
      "Training L2 (step):   0.45042\n",
      "Training L2 (full):   1.33538\n",
      "Testing L2 (step):    0.35723\n",
      "Testing L2 (full):    1.41073\n",
      "================================\n",
      "Epoch # 002 / 500\n",
      "Duration:      24.78823\n",
      "Training L2 (step):   0.28598\n",
      "Training L2 (full):   1.39070\n",
      "Testing L2 (step):    0.26935\n",
      "Testing L2 (full):    1.45236\n",
      "================================\n",
      "Epoch # 003 / 500\n",
      "Duration:      25.47932\n",
      "Training L2 (step):   0.23150\n",
      "Training L2 (full):   1.39994\n",
      "Testing L2 (step):    0.22702\n",
      "Testing L2 (full):    1.44580\n",
      "================================\n",
      "Epoch # 004 / 500\n",
      "Duration:      25.01301\n",
      "Training L2 (step):   0.19770\n",
      "Training L2 (full):   1.40148\n",
      "Testing L2 (step):    0.20557\n",
      "Testing L2 (full):    1.45377\n",
      "================================\n",
      "Epoch # 005 / 500\n",
      "Duration:      25.07817\n",
      "Training L2 (step):   0.17342\n",
      "Training L2 (full):   1.40091\n",
      "Testing L2 (step):    0.17774\n",
      "Testing L2 (full):    1.43436\n",
      "================================\n",
      "Epoch # 006 / 500\n",
      "Duration:      25.28796\n",
      "Training L2 (step):   0.15471\n",
      "Training L2 (full):   1.40114\n",
      "Testing L2 (step):    0.17177\n",
      "Testing L2 (full):    1.46208\n",
      "================================\n",
      "Epoch # 007 / 500\n",
      "Duration:      25.27147\n",
      "Training L2 (step):   0.14102\n",
      "Training L2 (full):   1.40266\n",
      "Testing L2 (step):    0.14914\n",
      "Testing L2 (full):    1.44426\n",
      "================================\n",
      "Epoch # 008 / 500\n",
      "Duration:      25.21264\n",
      "Training L2 (step):   0.13183\n",
      "Training L2 (full):   1.40300\n",
      "Testing L2 (step):    0.14049\n",
      "Testing L2 (full):    1.43652\n",
      "================================\n",
      "Epoch # 009 / 500\n",
      "Duration:      25.46231\n",
      "Training L2 (step):   0.12514\n",
      "Training L2 (full):   1.40316\n",
      "Testing L2 (step):    0.13928\n",
      "Testing L2 (full):    1.45002\n",
      "================================\n",
      "Epoch # 010 / 500\n",
      "Duration:      25.12114\n",
      "Training L2 (step):   0.11578\n",
      "Training L2 (full):   1.40372\n",
      "Testing L2 (step):    0.13914\n",
      "Testing L2 (full):    1.45366\n",
      "================================\n",
      "Epoch # 011 / 500\n",
      "Duration:      25.28691\n",
      "Training L2 (step):   0.11264\n",
      "Training L2 (full):   1.40383\n",
      "Testing L2 (step):    0.13644\n",
      "Testing L2 (full):    1.45789\n",
      "================================\n",
      "Epoch # 012 / 500\n",
      "Duration:      25.04800\n",
      "Training L2 (step):   0.10937\n",
      "Training L2 (full):   1.40380\n",
      "Testing L2 (step):    0.13083\n",
      "Testing L2 (full):    1.45104\n",
      "================================\n",
      "Epoch # 013 / 500\n",
      "Duration:      25.15237\n",
      "Training L2 (step):   0.10495\n",
      "Training L2 (full):   1.40401\n",
      "Testing L2 (step):    0.12359\n",
      "Testing L2 (full):    1.45360\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# training and evaluation\n",
    "################################################################\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=config.iterations\n",
    ")\n",
    "    \n",
    "lp_loss = LpLoss()  # By default, does not do size averaging\n",
    "output_encoder.cuda()\n",
    "for ep in range(config.epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_l2_step = 0\n",
    "    train_l2_full = 0\n",
    "    for train_data in train_loader:\n",
    "        # print({k: v.shape for k, v in train_data.items()})\n",
    "        xx = train_data['x'].to(device)\n",
    "        yy = train_data['y'].to(device)\n",
    "        loss = 0\n",
    "\n",
    "        # For each time step\n",
    "        for t in range(0, config.future_duration, config.step):\n",
    "            # We want the operator to learn the next S time steps:\n",
    "            y = yy[:, t:t + config.step, ...]\n",
    "            # use recurrent structure to propagate in time:\n",
    "            im = model(xx)\n",
    "            # print('y.shape=', y.shape)\n",
    "            # print('im.shape=', im.shape)\n",
    "            loss += lp_loss(\n",
    "                im.reshape(config.train_batch_size, -1),\n",
    "                y.reshape(config.train_batch_size, -1))\n",
    "\n",
    "            if t == 0:\n",
    "                pred = im\n",
    "            else:\n",
    "                pred = torch.cat((pred, im), -1)\n",
    "\n",
    "            # Advance the recurrent input by one time step; i.e:\n",
    "            # [t_n, ..., t_{n+m}] --> [t_{n+s}, ..., t_{n+s+m}]\n",
    "            # for starting time N, future duraiton M, and time step S\n",
    "\n",
    "            # xx0 = xx[..., config.step:-2, :, :]  # [t_{n+s}, ..., t_{n+m}]\n",
    "            # xx1 = im                             # [t_{n+m+1}, ..., t_{n+m+s}]\n",
    "            # xx2 = xx[..., -2:, :, :]              # positional encoding\n",
    "            # print('xx0.shape=', xx0.shape, '[t_{n+s}, ..., t_{n+m}]')\n",
    "            # print('xx1.shape=', xx1.shape, '[t_{n+m+1}, ..., t_{n+m+s}]')\n",
    "            # print('xx2.shape=', xx2.shape, '(positional encoding)')\n",
    "            xx = torch.cat((\n",
    "                xx[..., config.step:-2, :, :],  # [t_{n+s}, ..., t_{n+m}]\n",
    "                im,                             # [t_{n+m+1}, ..., t_{n+m+s}]\n",
    "                xx[..., -2:, :, :]              # positional encoding\n",
    "            ), dim=1)\n",
    "\n",
    "        # Compare the full, operator-predicted future with the ground truth.\n",
    "        # This is not used in training, but surfaces how well \n",
    "        # the operator has done overall in this epoch.\n",
    "        train_l2_step += loss.item()\n",
    "        l2_full = lp_loss(\n",
    "            pred.reshape(config.train_batch_size, -1), \n",
    "            yy.reshape(config.train_batch_size, -1))\n",
    "        train_l2_full += l2_full.item()\n",
    "\n",
    "        # Backprop based only on the loss for each step-by-step in time.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    test_l2_step = 0\n",
    "    test_l2_full = 0\n",
    "    with torch.no_grad():\n",
    "        for test_data in test_loader:\n",
    "            xx = test_data['x'].to(device)\n",
    "            yy = test_data['y'].to(device)\n",
    "            loss = 0\n",
    "\n",
    "            for t in range(0, config.future_duration, config.step):\n",
    "                y = yy[:, t:t + config.step, ...]\n",
    "                im = model(xx)\n",
    "                loss += lp_loss(\n",
    "                    im.reshape(config.test_batch_size, -1), \n",
    "                    y.reshape(config.test_batch_size, -1))\n",
    "\n",
    "                if t == 0:\n",
    "                    pred = im\n",
    "                else:\n",
    "                    pred = torch.cat((pred, im), -1)\n",
    "\n",
    "                xx = torch.cat((\n",
    "                    xx[..., config.step:-2, :, :],  # [t_{n+s}, ..., t_{n+m}]\n",
    "                    im,                             # [t_{n+m+1}, ..., t_{n+m+s}]\n",
    "                    xx[..., -2:, :, :]              # positional encoding\n",
    "                ), dim=1)\n",
    "\n",
    "            test_l2_step += loss.item()\n",
    "            test_l2_full += lp_loss(\n",
    "                pred.reshape(config.test_batch_size, -1), \n",
    "                yy.reshape(config.test_batch_size, -1)).item()\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(\n",
    "        f'Epoch # {ep:03d} / {config.epochs}',\n",
    "        f'Duration:           {t2 - t1:9.5f}',\n",
    "        f'Training L2 (step): {train_l2_step / config.n_train / (config.future_duration / config.step):9.5f}',\n",
    "        f'Training L2 (full): {train_l2_full / config.n_train:9.5f}',\n",
    "        f'Testing L2 (step):  {test_l2_step / config.n_test / (config.future_duration / config.step):9.5f}',\n",
    "        f'Testing L2 (full):  {test_l2_full / config.n_test:9.5f}',\n",
    "        '=' * 32,\n",
    "        sep='\\n',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Visualize the error in the trained model against a subsample of testing data points (i.e. field values from time t=0 to be mapped to t=1). Also visualize the error (squared to be non-negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass\n",
    "# test_samples = test_loader.dataset\n",
    "# n_rows = 3\n",
    "# n_cols = 5\n",
    "\n",
    "# fig = plt.figure(figsize=(13,  # width (inches)\n",
    "#                           9))  # height (inches)\n",
    "# for index in range(n_rows):\n",
    "#     data = test_samples[index]\n",
    "#     # Input x\n",
    "#     x = data['x'].cuda()\n",
    "#     # Ground-truth\n",
    "#     y = data['y'].cuda()\n",
    "#     # Model prediction\n",
    "#     out = model(x.unsqueeze(0))\n",
    "#     error = (out - y).square()\n",
    "#     error2 = (out / 2 - y).square()\n",
    "#     vmin = min(y.min(), out.min(), error.min(), error2.min())\n",
    "#     vmax = max(y.max(), out.max(), error.max(), error2.max())\n",
    "\n",
    "#     ax1 = fig.add_subplot(n_rows, n_cols, index * n_cols + 1)\n",
    "#     im1 = ax1.imshow(x[0].cpu(), cmap='gray')\n",
    "#     if index == 0:\n",
    "#         ax1.set_title('Input x')\n",
    "#     plt.xticks([], [])\n",
    "#     plt.yticks([], [])\n",
    "#     # fig.colorbar(im1, ax=ax1)\n",
    "\n",
    "#     ax2 = fig.add_subplot(n_rows, n_cols, index * n_cols + 2)\n",
    "#     im2 = ax2.imshow(y.squeeze().cpu(), cmap='magma', vmin=vmin, vmax=vmax)\n",
    "#     if index == 0:\n",
    "#         ax2.set_title('Ground-truth y')\n",
    "#     plt.xticks([], [])\n",
    "#     plt.yticks([], [])\n",
    "#     fig.colorbar(im2, ax=ax2)\n",
    "\n",
    "#     ax3 = fig.add_subplot(n_rows, n_cols, index * n_cols + 3)\n",
    "#     im3 = ax3.imshow(\n",
    "#         out.squeeze().detach().cpu(),\n",
    "#         cmap='magma',\n",
    "#         vmin=vmin,\n",
    "#         vmax=vmax\n",
    "#     )\n",
    "#     if index == 0:\n",
    "#         ax3.set_title('Model prediction')\n",
    "#     plt.xticks([], [])\n",
    "#     plt.yticks([], [])\n",
    "#     fig.colorbar(im3, ax=ax3)\n",
    "\n",
    "#     ax4 = fig.add_subplot(n_rows, n_cols, index * n_cols + 4)\n",
    "#     im4 = ax4.imshow(\n",
    "#         error.squeeze().detach().cpu(),\n",
    "#         cmap='magma',\n",
    "#         vmin=vmin,\n",
    "#         vmax=vmax\n",
    "#     )\n",
    "#     if index == 0:\n",
    "#         ax4.set_title('Error')\n",
    "#     plt.xticks([], [])\n",
    "#     plt.yticks([], [])\n",
    "#     fig.colorbar(im4, ax=ax4)\n",
    "    \n",
    "#     ax5 = fig.add_subplot(n_rows, n_cols, index * n_cols + 5)\n",
    "#     im5 = ax5.imshow(\n",
    "#         error2.squeeze().detach().cpu(),\n",
    "#         cmap='magma',\n",
    "#         vmin=vmin,\n",
    "#         vmax=vmax\n",
    "#     )\n",
    "#     if index == 0:\n",
    "#         ax5.set_title('Error (2)')\n",
    "#     plt.xticks([], [])\n",
    "#     plt.yticks([], [])\n",
    "#     fig.colorbar(im5, ax=ax5)\n",
    "    \n",
    "    \n",
    "# fig.suptitle('Inputs, ground-truth output and prediction.', y=0.98)\n",
    "# plt.tight_layout()\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
